{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information need to save in advance\n",
    "- Original Image\n",
    "- pos map\n",
    "- vertices\n",
    "- camera_matrix, pose, rotationmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:89: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n\nWARNING:tensorflow:From /home/vuthede/anaconda3/envs/rnn/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.__call__` method instead.\nWARNING:tensorflow:From ../../PRNet/predictor.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:91: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:91: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:94: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From ../../PRNet/predictor.py:75: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nINFO:tensorflow:Restoring parameters from ../../PRNet/Data/net-data/256_256_resfcn256_weight\n"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"../../PRNet\")\n",
    "from api import PRN\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # cpu\n",
    "prn = PRN(is_dlib = True, prefix=\"../../PRNet\")\n",
    "from utils.render import render_texture\n",
    "from utils.rotate_vertices import frontalize\n",
    "from utils.estimate_pose import estimate_pose\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Here is input:  (565, 565, 3)\nFinish dump one file\nTime: 3.2019810676574707\n"
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "def save_information(img, output):\n",
    "    pos = prn.process(img) \n",
    "    vertices = prn.get_vertices(pos)\n",
    "    cam_mat, pose, R = estimate_pose(vertices)\n",
    "\n",
    "    dictionary = {'img': img, 'pos':pos, 'vertices': vertices,\n",
    "                  'cam_mat': cam_mat, 'pose':pose, 'R': R}\n",
    "    pickle.dump(dictionary,open(output, 'wb'))\n",
    "    print(\"Finish dump one file\")\n",
    "\n",
    "t1 = time.time()\n",
    "save_information(cv2.imread('/home/vuthede/Desktop/3D/31_in.png'), \"tmp.pickle\")\n",
    "print(\"Time:\", time.time()-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_information(file):\n",
    "    return pickle.load(open(file, 'rb'))\n",
    "\n",
    "# info = load_information(\"tmp.pickle\")\n",
    "# info.keys()\n",
    "# texture_ref = cv2.remap(info['img']/255.0, info['pos'][:,:,:2].astype(np.float32), None, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT,borderValue=(0))\n",
    "\n",
    "# [h, w, c] = info['img'].shape\n",
    "    \n",
    "# color = prn.get_colors_from_texture(texture_ref)\n",
    "    \n",
    "# new_image = render_texture(info['vertices'].T, color.T, prn.triangles.T, h, w, c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "def save_information(img, output):\n",
    "    pos = prn.process(img) \n",
    "    vertices = prn.get_vertices(pos)\n",
    "    cam_mat, pose, R = estimate_pose(vertices)\n",
    "\n",
    "    dictionary = {'img': img, 'pos':pos, 'vertices': vertices,\n",
    "                  'cam_mat': cam_mat, 'pose':pose, 'R': R}\n",
    "    pickle.dump(dictionary,open(output, 'wb'))\n",
    "\n",
    "def save_3d_info_sync(video_synthesis, output=\"./synthesis\"):\n",
    "    if  not os.path.isdir(output):\n",
    "        os.makedirs(output)\n",
    "\n",
    "    obama_syn = cv2.VideoCapture(video_synthesis)\n",
    "    x1 = 685\n",
    "    y1 = 85\n",
    "    x2 = 1250\n",
    "    y2 = 650\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i+=1\n",
    "        for j in range(3):\n",
    "            ret, img_obama_syn = obama_syn.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(f\"Break at frame {i}\")\n",
    "            break\n",
    "        \n",
    "        img_obama_syn = cv2.resize(img_obama_syn, (x2-x1, y2-y1))\n",
    "        save_information(img_obama_syn,os.path.join(output, f'{i}.pickle' ))\n",
    "        print(f\"Finish dump one file {output}/{i}.pickle\")\n",
    "\n",
    "\n",
    "def save_3d_info_HD(video_HD, output=\"./HD\"):\n",
    "    if  not os.path.isdir(output):\n",
    "        os.makedirs(output)\n",
    "\n",
    "    obama_fullhd = cv2.VideoCapture(video_HD)\n",
    "    x1 = 685\n",
    "    y1 = 85\n",
    "    x2 = 1250\n",
    "    y2 = 650\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i+=1\n",
    "        for j in range(3):\n",
    "            ret1, img_obamahd = obama_fullhd.read()\n",
    "\n",
    "        if not ret1 or i>= 43*30:  # thus frame obama change view\n",
    "            print(f\"Break at frame {i}\")\n",
    "            break\n",
    "        \n",
    "        obama_crop = img_obamahd[y1:y2, x1:x2]\n",
    "        save_information(obama_crop,os.path.join(output, f'{i}.pickle' ))\n",
    "        print(f\"Finish dump one file {output}/{i}.pickle\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Here is input:  (565, 565, 3)\nFinish dump one file ./HD/1.pickle\nHere is input:  (565, 565, 3)\nFinish dump one file ./HD/2.pickle\nHere is input:  (565, 565, 3)\nFinish dump one file ./HD/3.pickle\nHere is input:  (565, 565, 3)\nFinish dump one file ./HD/4.pickle\nHere is input:  (565, 565, 3)\nFinish dump one file ./HD/5.pickle\nHere is input:  (565, 565, 3)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eb0b8f8fa20d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_3d_info_HD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/vuthede/AI/first-order-model/obama_fullhd.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b46c75486926>\u001b[0m in \u001b[0;36msave_3d_info_HD\u001b[0;34m(video_HD, output)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mobama_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_obamahd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msave_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobama_crop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{i}.pickle'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finish dump one file {output}/{i}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b46c75486926>\u001b[0m in \u001b[0;36msave_information\u001b[0;34m(img, output)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcam_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/PRNet/api.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input, image_info)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mdetected_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlib_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_faces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warning: no detected face'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/PRNet/api.py\u001b[0m in \u001b[0;36mdlib_detect\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdlib_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnet_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_3d_info_HD(\"/home/vuthede/AI/first-order-model/obama_fullhd.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_information(file):\n",
    "    return pickle.load(open(file, 'rb'))\n",
    "\n",
    "info = load_information(\"./HD/4.pickle\")\n",
    "info.keys()\n",
    "texture_ref = cv2.remap(info['img']/255.0, info['pos'][:,:,:2].astype(np.float32), None, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT,borderValue=(0))\n",
    "\n",
    "[h, w, c] = info['img'].shape\n",
    "    \n",
    "color = prn.get_colors_from_texture(texture_ref)\n",
    "    \n",
    "new_image = render_texture(info['vertices'].T, color.T, prn.triangles.T, h, w, c = 3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}